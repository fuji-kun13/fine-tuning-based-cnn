{"cells":[{"cell_type":"code","execution_count":null,"id":"63cb30af-baf0-465e-a134-b834d626774d","metadata":{"id":"63cb30af-baf0-465e-a134-b834d626774d"},"outputs":[],"source":["from gradcam import GradCAM, GradCAMpp\n","from gradcam.utils import visualize_cam\n","from torchvision.utils import make_grid, save_image\n","from PIL import Image, ImageDraw, ImageFont\n","import glob\n","import os\n","import torch.nn.functional as F\n","import torch\n","\n","# example\n","save_path = 'best_model.pth'\n","best_loss_model = models.resnet152(pretrained=True)\n","num_ftrs = best_loss_model.fc.in_features\n","best_loss_model.fc = nn.Linear(num_ftrs, 2)\n","best_loss_model.to(device)\n","best_loss_model.eval()\n","best_loss_model.load_state_dict(torch.load(save_path))\n","\n","target_layer = best_loss_model.layer4[-1]\n","gradcam = GradCAM(best_loss_model, target_layer)\n","gradcam_pp = GradCAMpp(best_loss_model, target_layer)\n","\n","# example\n","image_path = 'test_folder/*'\n","images = []\n","save_images = []\n","# example\n","save_dir = 'test_gradcam'\n","os.makedirs(save_dir, exist_ok=True)\n","\n","actual_label = 0\n","\n","classifications = []\n","\n","for i, path in enumerate(glob.glob(image_path)):\n","    img = Image.open(path)\n","    torch_img = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.Grayscale(num_output_channels=3),\n","        transforms.ToTensor()\n","    ])(img).to(device)\n","\n","    normed_torch_img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(torch_img)[None]\n","\n","    with torch.no_grad():\n","        output = best_loss_model(normed_torch_img)\n","        pred_probabilities = F.softmax(output, dim=1)\n","        pred_label = torch.argmax(pred_probabilities, dim=1).item()\n","        confidence = pred_probabilities[0, pred_label].item()\n","\n","    mask, _ = gradcam(normed_torch_img)\n","    heatmap, result = visualize_cam(mask, torch_img)\n","\n","    mask_pp, _ = gradcam_pp(normed_torch_img)\n","    heatmap_pp, result_pp = visualize_cam(mask_pp, torch_img)\n","\n","    black_image = Image.new(\"RGB\", (224, 224), \"gray\")\n","    draw = ImageDraw.Draw(black_image)\n","\n","    font_size = 15\n","    font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", font_size)\n","\n","    classification_text = f\"Pred: {pred_label}, Conf: {confidence:.2f}\"\n","\n","    draw.text((10, 100), classification_text, font=font, fill=(255, 255, 255))\n","\n","    black_image = transforms.ToTensor()(black_image)\n","\n","    images.extend([torch_img.cpu(), heatmap_pp, result_pp, black_image])\n","    save_images.extend([torch_img.cpu(), heatmap_pp, result_pp, black_image])\n","\n","    classifications.append({\n","        'index': i,\n","        'pred_label': pred_label,\n","        'actual_label': actual_label,\n","        'confidence': confidence\n","    })\n","\n","    if len(save_images) == 16:\n","        from torchvision.utils import save_image\n","        grid_image = make_grid(save_images, nrow=4)\n","        output_path = f\"gradcam_images_({i}).png\"\n","        save_image(grid_image, output_path)\n","\n","        print(f\"グリッド画像を {output_path} に保存しました。\")\n","        save_images = []\n","\n","grid_image = make_grid(images, nrow=4)\n","transforms.ToPILImage()(grid_image).show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}