{"cells":[{"cell_type":"code","execution_count":null,"id":"300d74c6","metadata":{"id":"300d74c6"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n","from sklearn import metrics\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve\n","import numpy as np\n","import random\n","from torch.utils.data import DataLoader, Subset\n","from torchvision.datasets import ImageFolder\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"id":"0a2768c1","metadata":{"id":"0a2768c1"},"outputs":[],"source":["print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"id":"6cb805cb-7919-44e7-ba4b-b7ac2409de9a","metadata":{"id":"6cb805cb-7919-44e7-ba4b-b7ac2409de9a"},"outputs":[],"source":["def torch_fix_seed(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.use_deterministic_algorithms = True\n","\n","torch_fix_seed()"]},{"cell_type":"code","execution_count":null,"id":"2b4dd140","metadata":{"id":"2b4dd140"},"outputs":[],"source":["data_transform = {\n","    'train': transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.RandomRotation(degrees=[-90, 90]),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n","        transforms.Grayscale(num_output_channels=3),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.Grayscale(num_output_channels=3),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","}\n","\n","batch_size = 8\n","\n","dataset = ImageFolder(root='train_folder')\n","\n","test_dataset = ImageFolder(root='test_folder', transform=data_transform['val'])\n","test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"18fdfe21","metadata":{"id":"18fdfe21"},"outputs":[],"source":["print(len(dataset))\n","print(len(test_dataset))"]},{"cell_type":"code","execution_count":null,"id":"ed9ccf60-601e-43e2-ad87-46d7685dd49f","metadata":{"id":"ed9ccf60-601e-43e2-ad87-46d7685dd49f"},"outputs":[],"source":["kf = KFold(n_splits=5, shuffle=True, random_state=1)\n","\n","best_model_accuracy = 0.0\n","best_acc_model = None\n","best_model_name = \"\"\n","best_model_loss = float('inf')\n","best_loss_model = None\n","best_model_name = \"\"\n","\n","for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n","    best_val_loss = float('inf')\n","    print(f'Fold {fold + 1}')\n","\n","    train_subset = Subset(dataset, train_idx)\n","    val_subset = Subset(dataset, val_idx)\n","\n","    train_subset.dataset.transform = data_transform['train']\n","    val_subset.dataset.transform = data_transform['val']\n","\n","    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=256, shuffle=False)\n","\n","\n","    # example\n","    save_path = 'best_model.pth'\n","    pretrained_model = models.resnet101(pretrained=True)\n","    num_ftrs = pretrained_model.fc.in_features\n","    pretrained_model.fc = nn.Linear(num_ftrs, 2)\n","\n","\n","    parameters_to_update = pretrained_model.parameters()\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    pretrained_model = pretrained_model.to(device)\n","\n","    optimizer = optim.Adam(parameters_to_update, lr=1e-4)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    num_epochs = 50\n","    early_stopping_patience = 10\n","    no_improvement_count = 0\n","\n","    for epoch in range(num_epochs):\n","        pretrained_model.train()\n","        running_loss = 0.0\n","        correct_predictions = 0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = pretrained_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct_predictions += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_acc = correct_predictions.double() / len(train_loader.dataset)\n","\n","        print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","        pretrained_model.eval()\n","        val_loss = 0.0\n","        val_corrects = 0\n","\n","        with torch.no_grad():\n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = pretrained_model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item() * inputs.size(0)\n","                _, preds = torch.max(outputs, 1)\n","                val_corrects += torch.sum(preds == labels.data)\n","\n","        val_loss /= len(val_loader.dataset)\n","        val_acc = val_corrects.double() / len(val_loader.dataset)\n","\n","        print(f'Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            no_improvement_count = 0\n","            if best_val_loss < best_model_loss:\n","                best_model_loss = best_val_loss\n","                torch.save(pretrained_model.state_dict(), save_path)\n","        else:\n","            no_improvement_count += 1\n","\n","        if no_improvement_count >= early_stopping_patience:\n","            print(f'Early stopping at epoch {epoch + 1}')\n","            break"]},{"cell_type":"code","execution_count":null,"id":"fba43ffd-696b-470e-bc74-9ebbdbd10581","metadata":{"id":"fba43ffd-696b-470e-bc74-9ebbdbd10581"},"outputs":[],"source":["print(f'Best Accuracy: {best_model_accuracy:.4f}')\n","print(f'Best Loss: {best_model_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"id":"7173f7ec-fb4e-44fb-90f4-8b99d1f38e07","metadata":{"id":"7173f7ec-fb4e-44fb-90f4-8b99d1f38e07"},"outputs":[],"source":["y_true = []\n","y_pred = []\n","y_probs = []\n","\n","\n","best_loss_model = models.resnet101(pretrained=True)\n","num_ftrs = best_loss_model.fc.in_features\n","best_loss_model.fc = nn.Linear(num_ftrs, 2)\n","\n","best_loss_model.to(device)\n","best_loss_model.load_state_dict(torch.load(save_path))\n","\n","best_loss_model.eval()\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = best_loss_model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","\n","        probabilities = nn.functional.softmax(outputs, dim=1)\n","        y_probs.extend(probabilities.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"id":"f13faef9-7f1a-4a4e-b445-c59eafdd7732","metadata":{"id":"f13faef9-7f1a-4a4e-b445-c59eafdd7732"},"outputs":[],"source":["cm = confusion_matrix(y_true, y_pred)\n","print('Confusion Matrix:')\n","print(cm)\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","# example\n","plt.xticks([0.5, 1.5], ['label1','label2'])\n","plt.yticks([0.5, 1.5], ['label1','label2'])\n","\n","plt.savefig('Confusion_Matrix')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"5a682e1f","metadata":{"id":"5a682e1f"},"outputs":[],"source":["report = classification_report(y_true, y_pred, target_names=test_dataset.classes)\n","print('Classification Report:')\n","print(report)\n","\n","y_true = np.array(y_true)\n","y_prob = np.array(y_probs)\n","\n","C = confusion_matrix(y_true, y_pred)\n","ac = accuracy_score(y_true, y_pred)\n","pre = precision_score(y_true, y_pred, average='macro')\n","re = recall_score(y_true, y_pred, average='macro')\n","f1 = f1_score(y_true, y_pred, average='macro')\n","AUC = roc_auc_score(y_true, y_prob[:,1])\n","\n","print(C)\n","print(\"\\n\")\n","print(\"test accuracy : %.3f\" % ac)\n","print(\"test precision : %.3f\" % pre)\n","print(\"test recall : %.3f\" % re)\n","print(\"test F1 : %.3f\" % f1)\n","print(\"AUC : %.3f\" % AUC)"]},{"cell_type":"code","execution_count":null,"id":"3d256154-e6b8-4413-ba94-20f12308f76a","metadata":{"id":"3d256154-e6b8-4413-ba94-20f12308f76a"},"outputs":[],"source":["# example\n","save_path_list = [\n","    'best_model_1.pth',\n","    'best_model_2.pth',\n","    'best_model_3.pth',\n","    'best_model_4.pth',\n","    'best_model_5.pth',\n","]\n","def get_model(save_path):\n","    if 'resnet101' in save_path:\n","        model = models.resnet101(pretrained=True)\n","        num_ftrs = model.fc.in_features\n","        model.fc = nn.Linear(num_ftrs, 2)\n","\n","    elif 'resnet152' in save_path:\n","        model = models.resnet152(pretrained=True)\n","        num_ftrs = model.fc.in_features\n","        model.fc = nn.Linear(num_ftrs, 2)\n","\n","    elif 'efficientnet' in save_path:\n","        model = EfficientNet.from_pretrained('efficientnet-b0')\n","        num_ftrs = model._fc.in_features\n","        model._fc = nn.Linear(num_ftrs, 2)\n","\n","    elif 'mobilenet_v2' in save_path:\n","        model = models.mobilenet_v2(pretrained=True)\n","        num_ftrs = model.classifier[1].in_features\n","        model.classifier[1] = nn.Linear(num_ftrs, 2)\n","\n","    elif 'mobilenet_v3_large' in save_path:\n","        model = models.mobilenet_v3_large(pretrained=True)\n","        num_ftrs = model.classifier[3].in_features\n","        model.classifier[3] = nn.Linear(num_ftrs, 2)\n","\n","    elif 'densenet169' in save_path:\n","        model = models.densenet169(pretrained=True)\n","        num_ftrs = model.classifier.in_features\n","        model.classifier = nn.Linear(num_ftrs, 2)\n","\n","    elif 'densenet201' in save_path:\n","        model = models.densenet201(pretrained=True)\n","        num_ftrs = model.classifier.in_features\n","        model.classifier = nn.Linear(num_ftrs, 2)\n","\n","    elif 'wide_resnet101_2' in save_path:\n","        model = models.wide_resnet101_2(pretrained=True)\n","        num_ftrs = model.fc.in_features\n","        model.fc = nn.Linear(num_ftrs, 2)\n","\n","    else:\n","        raise ValueError(f\"Unsupported model path: {save_path}\")\n","\n","    return model\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","threshold = 0.5\n","\n","all_predictions = []\n","all_probabilities = []\n","y_true = []\n","\n","for save_path in save_path_list:\n","    print(f\"Evaluating model: {save_path}\")\n","\n","    model = get_model(save_path).to(device)\n","    model.load_state_dict(torch.load(save_path))\n","    model.eval()\n","\n","    model_predictions = []\n","    model_probabilities = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            probabilities = nn.functional.softmax(outputs, dim=1)\n","            preds = (probabilities[:, 1] >= threshold).long()\n","\n","            model_predictions.extend(preds.cpu().numpy())\n","            model_probabilities.extend(probabilities[:, 1].cpu().numpy())\n","\n","            if len(y_true) == 0:\n","                y_true.extend(labels.cpu().numpy())\n","\n","    all_predictions.append(model_predictions)\n","    all_probabilities.append(model_probabilities)\n","\n","all_predictions = np.array(all_predictions)\n","final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_predictions)\n","\n","all_probabilities = np.array(all_probabilities)\n","final_probabilities = np.mean(all_probabilities, axis=0)\n","\n","y_true = np.array(y_true)\n","C = confusion_matrix(y_true, final_predictions)\n","ac = accuracy_score(y_true, final_predictions)\n","pre = precision_score(y_true, final_predictions, average='macro')\n","re = recall_score(y_true, final_predictions, average='macro')\n","f1 = f1_score(y_true, final_predictions, average='macro')\n","\n","AUC = roc_auc_score(y_true, final_probabilities)\n","\n","print(\"Confusion Matrix:\")\n","print(C)\n","print(\"\\nMetrics:\")\n","print(f\"Accuracy: {ac:.3f}\")\n","print(f\"Precision: {pre:.3f}\")\n","print(f\"Recall: {re:.3f}\")\n","print(f\"F1 Score: {f1:.3f}\")\n","print(f\"AUC: {AUC:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"901c00dd-2ee7-4d36-abdf-e116680feabc","metadata":{"id":"901c00dd-2ee7-4d36-abdf-e116680feabc"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import KFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset\n","from torchvision import models\n","\n","data_transform = {\n","    'train': transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.RandomRotation(degrees=[-90, 90]),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n","        transforms.Grayscale(num_output_channels=3),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.Grayscale(num_output_channels=3),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","}\n","\n","dataset = ImageFolder(root='train_folder', transform=data_transform['train'])\n","test_dataset = ImageFolder(root='test_folder', transform=data_transform['val'])\n","\n","batch_size = 8\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# example\n","classes = (\"label1\", \"label2\")\n","\n","# example\n","base_models = {\n","    \"mobilenet_v2\": models.mobilenet_v2(pretrained=True),\n","    \"resnet101\": models.resnet101(pretrained=True),\n","    \"densenet169\": models.densenet169(pretrained=True),\n","}\n","num_classes = 2\n","for name, model in base_models.items():\n","    if \"resnet\" in name:\n","        num_ftrs = model.fc.in_features\n","        model.fc = nn.Linear(num_ftrs, num_classes)\n","    elif \"densenet\" in name:\n","        num_ftrs = model.classifier.in_features\n","        model.classifier = nn.Linear(num_ftrs, num_classes)\n","    elif \"mobilenet_v2\" in name:\n","        num_ftrs = model.classifier[1].in_features\n","        model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","for model in base_models.values():\n","    model.to(device)\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=1)\n","\n","meta_features = []\n","meta_labels = []\n","\n","for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n","    print(f\"Fold {fold + 1}\")\n","\n","    train_subset = Subset(dataset, train_idx)\n","    val_subset = Subset(dataset, val_idx)\n","\n","    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n","\n","    fold_meta_features = []\n","    fold_meta_labels = [dataset.targets[idx] for idx in val_idx]\n","\n","    for model_name, model in base_models.items():\n","\n","        print(f\"Training {model_name}...\")\n","\n","        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","        criterion = nn.CrossEntropyLoss()\n","\n","        num_epochs = 20\n","        model.train()\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            correct_predictions = 0\n","            for inputs, labels in train_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                _, preds = torch.max(outputs, 1)\n","                correct_predictions += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(train_loader.dataset)\n","            epoch_acc = correct_predictions.double() / len(train_loader.dataset)\n","\n","            print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","        model.eval()\n","        val_outputs = []\n","        with torch.no_grad():\n","            for inputs, _ in val_loader:\n","                inputs = inputs.to(device)\n","                outputs = model(inputs)\n","                val_outputs.append(outputs.cpu().numpy())\n","\n","        val_outputs = np.concatenate(val_outputs, axis=0)\n","        if len(val_outputs) != len(fold_meta_labels):\n","            raise ValueError(\n","                f\"Model {model_name} output size ({len(val_outputs)}) does not match validation labels size ({len(fold_meta_labels)})\"\n","            )\n","        fold_meta_features.append(val_outputs)\n","\n","    fold_meta_features = np.concatenate(fold_meta_features, axis=1)\n","    meta_features.append(fold_meta_features)\n","    meta_labels.append(fold_meta_labels)\n","\n","meta_features = np.concatenate(meta_features, axis=0)\n","meta_labels = np.concatenate(meta_labels)\n","\n","meta_model = LogisticRegression()\n","meta_model.fit(meta_features, meta_labels)\n","\n","meta_test_features = []\n","for model_name, model in base_models.items():\n","    model.eval()\n","    test_outputs = []\n","    with torch.no_grad():\n","        for inputs, _ in test_loader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            test_outputs.append(outputs.cpu().numpy())\n","\n","    test_outputs = np.concatenate(test_outputs, axis=0)\n","    meta_test_features.append(test_outputs)\n","\n","meta_test_features = np.concatenate(meta_test_features, axis=1)\n","test_predictions = meta_model.predict(meta_test_features)\n","\n","test_labels = [label for _, label in test_dataset]\n","accuracy = accuracy_score(test_labels, test_predictions)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"cd3de4b0-8387-4943-a02e-6313fd5794bd","metadata":{"id":"cd3de4b0-8387-4943-a02e-6313fd5794bd"},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n","import joblib\n","\n","print(\"Classification Report:\")\n","print(classification_report(test_labels, test_predictions, target_names=classes, digits=3))\n","\n","conf_matrix = confusion_matrix(test_labels, test_predictions)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","ac = accuracy_score(test_labels, test_predictions)\n","pre = precision_score(test_labels, test_predictions, average='macro')\n","re = recall_score(test_labels, test_predictions, average='macro')\n","f1 = f1_score(test_labels, test_predictions, average='macro')\n","\n","print(f\"Accuracy: {ac:.3f}\")\n","print(f\"Precision: {pre:.3f}\")\n","print(f\"Recall: {re:.3f}\")\n","print(f\"F1 Score: {f1:.3f}\")\n","\n","test_probabilities = meta_model.predict_proba(meta_test_features)\n","if len(classes) == 2:\n","    auc_score = roc_auc_score(test_labels, test_probabilities[:, 1])\n","else:\n","    auc_score = roc_auc_score(test_labels, test_probabilities, multi_class=\"ovr\")\n","print(f\"AUC Score: {auc_score:.3f}\")\n","\n","# example\n","meta_model_path = \"meta_model.pkl\"\n","joblib.dump(meta_model, meta_model_path)\n","print(f\"Meta-model saved to {meta_model_path}\")\n"]},{"cell_type":"code","execution_count":null,"id":"d2c2a25c-417e-4b5b-8ed5-ade0c3856b23","metadata":{"id":"d2c2a25c-417e-4b5b-8ed5-ade0c3856b23"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","import joblib\n","import shutil\n","\n","def classify_and_save_1st_stage(dataloader, dataset, output_dir=\"classified_data_1and2vs3\"):\n","    grade1_2_dir = os.path.join(output_dir, \"grade1_2\")\n","    grade3_dir = os.path.join(output_dir, \"grade3\")\n","\n","    os.makedirs(grade1_2_dir, exist_ok=True)\n","    os.makedirs(grade3_dir, exist_ok=True)\n","\n","    meta_model_path = \"meta_model.pkl\"\n","    meta_model = joblib.load(meta_model_path)\n","    print(f\"Loaded meta-model from {meta_model_path}\")\n","\n","    meta_test_features = []\n","    image_paths = [path for path, _ in dataset.samples]\n","    image_filenames = [os.path.basename(path) for path in image_paths]\n","\n","    for model_name, model in base_models.items():\n","        model.eval()\n","        test_outputs = []\n","        with torch.no_grad():\n","            for inputs, _ in dataloader:\n","                inputs = inputs.to(device)\n","                outputs = model(inputs)\n","                test_outputs.append(outputs.cpu().numpy())\n","\n","        test_outputs = np.concatenate(test_outputs, axis=0)\n","        meta_test_features.append(test_outputs)\n","\n","    meta_test_features = np.concatenate(meta_test_features, axis=1)\n","    preds = meta_model.predict(meta_test_features)\n","    print(preds)\n","    for img_path, pred in zip(image_paths, preds):\n","        folder = grade1_2_dir if pred == 0 else grade3_dir\n","        save_path = os.path.join(folder, os.path.basename(img_path))\n","        shutil.copy2(img_path, save_path)\n","\n","    print(\"✅ 1st stage classification completed and images saved.\")\n","\n","    return preds, grade1_2_dir, grade3_dir\n"]},{"cell_type":"code","execution_count":null,"id":"f9aa3cc5-dee5-4bf2-be69-ad98bf7c23bc","metadata":{"id":"f9aa3cc5-dee5-4bf2-be69-ad98bf7c23bc"},"outputs":[],"source":["preds_1st, grade1_2_dir, grade3_dir = classify_and_save_1st_stage(test_loader, test_dataset)"]},{"cell_type":"code","execution_count":null,"id":"f0371230-b856-4e28-90df-7612b4de4b9a","metadata":{"id":"f0371230-b856-4e28-90df-7612b4de4b9a"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from torchvision import models\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n","\n","def load_model(model_path, model_type):\n","    if model_type == \"resnet101\":\n","        model = models.resnet101(pretrained=True)\n","        num_ftrs = model.fc.in_features\n","        model.fc = nn.Linear(num_ftrs, 2)\n","    elif model_type == \"densenet169\":\n","        model = models.densenet169(pretrained=True)\n","        num_ftrs = model.classifier.in_features\n","        model.classifier = nn.Linear(num_ftrs, 2)\n","    else:\n","        raise ValueError(f\"Unsupported model type: {model_type}\")\n","\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","    return model.to(device)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"ac7c5615-8f54-4e33-b4f9-f57e639955b0","metadata":{"id":"ac7c5615-8f54-4e33-b4f9-f57e639955b0"},"outputs":[],"source":["def classify_and_save_2st_stage(output_dir=\"classified_data_1and2vs3\", threshold=0.5, batch_size=8):\n","    test_dataset_2nd_stage = ImageFolder(root='classified_data_1and2vs3/test_1vs2', transform=data_transform['val'])\n","    test_loader_2nd_stage  = DataLoader(test_dataset_2nd_stage, batch_size=batch_size, shuffle=False)\n","    print(len(test_dataset_2nd_stage))\n","\n","    grade1_dir = os.path.join(output_dir, \"grade1\")\n","    grade2_dir = os.path.join(output_dir, \"grade2\")\n","\n","    os.makedirs(grade1_dir, exist_ok=True)\n","    os.makedirs(grade2_dir, exist_ok=True)\n","\n","    image_filenames = [os.path.basename(path) for path, _ in test_dataset_2nd_stage.samples]\n","\n","    # example\n","    model_2nd = load_model(\"model_cnn_densenet169/best_model.pth\", \"densenet169\")\n","\n","    y_true = []\n","    y_pred = []\n","    y_probs = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader_2nd_stage:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model_2nd(inputs)\n","            probabilities = nn.functional.softmax(outputs, dim=1)\n","            preds = (probabilities[:, 1] >= threshold).long()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(preds.cpu().numpy())\n","\n","            probabilities = nn.functional.softmax(outputs, dim=1)\n","            y_probs.extend(probabilities.cpu().numpy())\n","\n","    preds_batches = [y_pred[i:i + batch_size] for i in range(0, len(y_pred), batch_size)]\n","    image_filenames_batches = [image_filenames[i:i + batch_size] for i in range(0, len(image_filenames), batch_size)]\n","    image_paths = [path for path, _ in test_dataset_2nd_stage.samples]\n","\n","    print(y_pred)\n","    print(preds_batches)\n","    for img_path, pred in zip(image_paths, y_pred):\n","        folder = grade1_dir if pred == 0 else grade2_dir\n","        save_path = os.path.join(folder, os.path.basename(img_path))\n","        shutil.copy2(img_path, save_path)\n","\n","    print(\"✅ 2nd stage classification completed and images saved.\")\n","\n","    return y_pred"]},{"cell_type":"code","execution_count":null,"id":"443e8a2c-8d5c-414f-aa25-328f1788ac59","metadata":{"id":"443e8a2c-8d5c-414f-aa25-328f1788ac59"},"outputs":[],"source":["preds_2nd = classify_and_save_2st_stage()"]},{"cell_type":"code","execution_count":null,"id":"f8946648-97ab-4660-9597-501c84f88a48","metadata":{"id":"f8946648-97ab-4660-9597-501c84f88a48"},"outputs":[],"source":["# example\n","y_true = []\n","for i in range(18):\n","    y_true.append(0)\n","for i in range(20):\n","    y_true.append(1)\n","for i in range(20):\n","    y_true.append(2)\n","print(y_true)\n","final_predictions =  [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1]\n","final_predictions += [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2]\n","final_predictions += [0,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]\n","\n","C = confusion_matrix(y_true, final_predictions)\n","ac = accuracy_score(y_true, final_predictions)\n","pre = precision_score(y_true, final_predictions, average='macro')\n","re = recall_score(y_true, final_predictions, average='macro')\n","f1 = f1_score(y_true, final_predictions, average='macro')\n","\n","print(y_true)\n","print(final_predictions)\n","print(\"Confusion Matrix:\")\n","print(C)\n","print(\"\\nMetrics:\")\n","print(f\"Accuracy: {ac:.3f}\")\n","print(f\"Precision: {pre:.3f}\")\n","print(f\"Recall: {re:.3f}\")\n","print(f\"F1 Score: {f1:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"ce5ad330-b477-4e54-9444-18c58253eb8e","metadata":{"id":"ce5ad330-b477-4e54-9444-18c58253eb8e"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(C, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Grade 1\", \"Grade 2\", \"Grade 3\"], yticklabels=[\"Grade 1\", \"Grade 2\", \"Grade 3\"])\n","\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","\n","plt.savefig('confusion_matrix')\n","\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}